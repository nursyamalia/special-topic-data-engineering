{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Flickr Web Scraping: Clouds image ☁️"
      ],
      "metadata": {
        "id": "rWrXzWFeGxtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flickrapi"
      ],
      "metadata": {
        "id": "QVltfQ2nq0q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47243ac3-7de1-4881-e517-3f385204b72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flickrapi\n",
            "  Downloading flickrapi-2.4.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from flickrapi) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.9/dist-packages (from flickrapi) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from flickrapi) (1.3.1)\n",
            "Collecting requests-toolbelt>=0.3.1\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.2.1->flickrapi) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.2.1->flickrapi) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.2.1->flickrapi) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.2.1->flickrapi) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.4.0->flickrapi) (3.2.2)\n",
            "Installing collected packages: requests-toolbelt, flickrapi\n",
            "Successfully installed flickrapi-2.4.0 requests-toolbelt-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import flickrapi\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5Iz1odtbqf1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dline(operator):\n",
        "    if operator == 0:\n",
        "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
        "    elif operator == 1:\n",
        "        print('----------------------------------------------------------------------------------')\n",
        "    elif operator == 2:\n",
        "        print('\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
        "    return"
      ],
      "metadata": {
        "id": "uCpf154LMSWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create folder path\n",
        "def mkdir(root,folder):\n",
        "    path = root+'/'+folder\n",
        "    folder = os.path.exists(path)\n",
        "    if not folder:\n",
        "        os.makedirs(path)\n",
        "        os.chdir(path)\n",
        "    else:\n",
        "        os.chdir(path)\n",
        "        pass\n",
        "    return path"
      ],
      "metadata": {
        "id": "HD1ABBh1uFyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get tags\n",
        "def get_tags(url_base):\n",
        "    res = requests.get(url_base + '/photos/tags')\n",
        "    res.encoding = 'utf-8'\n",
        "    hsoup = BeautifulSoup(res.text,'html.parser')\n",
        "    \n",
        "    tag_lst = []\n",
        "    for tag in hsoup.select('.overlay'):\n",
        "        tag_lst.append(tag.text)\n",
        "    for i in range(len(tag_lst)):\n",
        "        if tag_lst[i] == 'clouds':\n",
        "            tag_lst = tag_lst[i:][:10]\n",
        "            print('TAG_LIST ABSORBED !')\n",
        "            print(tag_lst)\n",
        "            dline(1)\n",
        "            break\n",
        "    time.sleep(0.5)\n",
        "    return tag_lst"
      ],
      "metadata": {
        "id": "Gq6RUm0srOyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_base = 'https://www.flickr.com'\n",
        "api_key = 'e6b00be365cab3b2c004788b12bb6b47'\n",
        "api_secret = '401e90577d12f507'\n",
        "root = '/content/sample_data'\n",
        "min_date = '2022-01-01'\n",
        "tag_lst = get_tags(url_base)"
      ],
      "metadata": {
        "id": "dWQUdTICqgSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f937dbb4-63c7-44c2-a1ea-9a70fc3d8931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TAG_LIST ABSORBED !\n",
            "['clouds', 'cat', 'summer', 'street', 'park', 'winter', 'landscape', 'flowers', 'pink', 'snow']\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get photo id\n",
        "def get_pic(tag,min_date,api_key,api_secret):\n",
        "    st = time.process_time()\n",
        "    flickr=flickrapi.FlickrAPI(api_key,api_secret,cache=True)      \n",
        "    \n",
        "    try:\n",
        "        photos = flickr.walk(tags=tag,\n",
        "                           sort='interestingness-desc',\n",
        "                           content_type='1',\n",
        "                           extras='views',\n",
        "                           min_upload_date=min_date)\n",
        "    except Exception as e:\n",
        "        time.sleep(1800)\n",
        "        print('get_pic()',e)\n",
        "\n",
        "    file_name = tag + '_id.csv'\n",
        "    df_pic = pd.DataFrame()\n",
        "    total = 0\n",
        "    amount = 0\n",
        "    drop_nan = 0\n",
        "\n",
        "    for photo in photos:\n",
        "            \n",
        "        exist = (float(str(photo.get('views').strip()))!= 0)\n",
        "        if exist:\n",
        "            df_temp = pd.DataFrame()\n",
        "            df_temp['pic_id'] = pd.Series(str(photo.get('id')))\n",
        "            df_temp['Views'] = pd.Series(float(str(photo.get('views').strip())))\n",
        "            df_pic = pd.concat([df_pic,df_temp])\n",
        "            amount += 1\n",
        "        else:\n",
        "            drop_nan += 1\n",
        "        \n",
        "        df_pic['tag'] = tag\n",
        "        df_pic.to_csv(file_name,sep=',',index=False,header=None,mode='a')\n",
        "        df_pic = pd.DataFrame()\n",
        "        \n",
        "        total += 1\n",
        "        st_pic = round(time.process_time() - st,2)\n",
        "        print('\\rGETTING PICS: {0} , DROP_NAN: {1} , TOTAL: {2} , TIME CONSUMED: {3}s'.format(amount,drop_nan,total,st_pic),end='',flush=True)\n",
        "        time.sleep(0.1)\n",
        "        #if amount >= 20:\n",
        "            #break\n",
        "        #else:\n",
        "            #pass\n",
        "    print('\\nPIC_SET: %s SAVED !' %tag)\n",
        "    dline(1)\n",
        "    return"
      ],
      "metadata": {
        "id": "MjsH7rqrvm9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tag in tag_lst:\n",
        "    path = mkdir(root,'IDs_Views')\n",
        "    file_path = path + '/' + tag + '_id.csv'\n",
        "    exist = os.path.exists(file_path)\n",
        "\n",
        "    if exist:\n",
        "        print('TAG: %s ALREADY ABSORBED !' %tag)\n",
        "        dline(1)\n",
        "        pass\n",
        "    else:\n",
        "        print('CRAWLING ON TAG: %s...' %tag)\n",
        "        dline(0)\n",
        "        get_pic(tag,min_date,api_key,api_secret)\n",
        "        time.sleep(2000)\n",
        "    \n",
        "print('FINISH !!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "7TILxbQa1xBg",
        "outputId": "948d249c-4984-4ee1-db36-3fd685cf3499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRAWLING ON TAG: clouds...\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "GETTING PICS: 634 , DROP_NAN: 0 , TOTAL: 634 , TIME CONSUMED: 4.87s"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9125ddcbb64c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CRAWLING ON TAG: %s...'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mget_pic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapi_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f33fc7615944>\u001b[0m in \u001b[0;36mget_pic\u001b[0;34m(tag, min_date, api_key, api_secret)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mst_pic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\rGETTING PICS: {0} , DROP_NAN: {1} , TOTAL: {2} , TIME CONSUMED: {3}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_nan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst_pic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#if amount >= 20:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Exif info\n",
        "def get_exif(df_pic,file_name,api_key,api_secret):\n",
        "    st = time.process_time()\n",
        "    file_name = file_name.replace('id','exif')\n",
        "    df_info = pd.DataFrame(columns=['pic_id','Camera_Make','Camera_Model',\n",
        "                                    'Exposure','Aperture','Exposure_Program',\n",
        "                                    'ISO','Metering_Mode','Flash','Focal_Length',\n",
        "                                    'Color_Space','Lens_Model'])\n",
        "    df_info.to_csv(file_name,sep=',',index=None)\n",
        "    total = 0\n",
        "    amount = 0\n",
        "    drop_nan = 0\n",
        "        \n",
        "    for i in range(len(df_pic.index)):\n",
        "            \n",
        "        if amount < 100000:\n",
        "            try:\n",
        "                flickr=flickrapi.FlickrAPI(api_key,api_secret,format='parsed-json')\n",
        "                exif = flickr.photos.getExif(photo_id=df_pic['pic_id'].iloc[i])\n",
        "                \n",
        "                for info in exif['photo']['exif']:\n",
        "                    if info['label'] == 'Make':\n",
        "                        df_info['Camera_Make'] = pd.Series(info['raw']['_content'])\n",
        "                    elif info['label'] == 'Model':\n",
        "                        df_info['Camera_Model'] = pd.Series(info['raw']['_content'])\n",
        "                    elif info['label'] == 'Exposure':\n",
        "                        if '/' in info['raw']['_content']:\n",
        "                            operator = info['raw']['_content'].strip().split('/')\n",
        "                            df_info['Exposure'] = pd.Series(float(operator[0])/float(operator[1]))\n",
        "                        else:\n",
        "                            df_info['Exposure'] = pd.Series(float(info['raw']['_content'].strip()))\n",
        "                    elif info['label'] == 'Aperture':\n",
        "                        df_info['Aperture'] = pd.Series(float(info['raw']['_content'].strip()))\n",
        "                    elif info['label'] == 'Exposure Program':\n",
        "                        df_info['Exposure_Program'] = pd.Series(info['raw']['_content'])\n",
        "                    elif info['label'] == 'ISO Speed':\n",
        "                        df_info['ISO'] = pd.Series(float(info['raw']['_content'].strip()))\n",
        "                    elif info['label'] == 'Metering Mode':\n",
        "                        df_info['Metering_Mode'] = pd.Series(info['raw']['_content'])\n",
        "                    elif info['label'] == 'Flash':\n",
        "                        df_info['Flash'] = pd.Series(info['raw']['_content'])\n",
        "                    elif info['label'] == 'Focal Length':\n",
        "                        df_info['Focal_Length'] = pd.Series(float(info['raw']['_content'].replace('mm','').strip()))\n",
        "                    elif info['label'] == 'Color Space':\n",
        "                        df_info['Color_Space'] = pd.Series(info['raw']['_content'])\n",
        "                    elif info['label'] == 'Lens Model':\n",
        "                        df_info['Lens_Model'] = pd.Series(info['raw']['_content'])\n",
        "                \n",
        "                df_info['pic_id'] = df_pic['pic_id'].iloc[i]\n",
        "                df_info.to_csv(file_name,sep=',',index=None,header=None,mode='a')\n",
        "                amount += 1\n",
        "            except Exception as e:\n",
        "                drop_nan += 1\n",
        "                pass\n",
        "            \n",
        "        else:\n",
        "            break\n",
        "        total += 1\n",
        "        st_info = round(time.process_time()-st,2)\n",
        "        print('\\rGETTING INFO: {0} , DROP_NAN: {1} , TOTAL: {2} , TIME CONSUMED: {3}s'.format(amount,drop_nan,total,st_info),end='',flush=True)\n",
        "        #time.sleep(1)\n",
        "    dline(2)\n",
        "    print('FILE: %s SAVED !' %file_name)\n",
        "    print('SIZE: %i' %amount)\n",
        "    \n",
        "    return\n"
      ],
      "metadata": {
        "id": "byaDnGJ-Tpag"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '2b74061345250898719cdc9cf9aae8f0'\n",
        "api_secret = '0825a78a0bd5865e'\n",
        "root = '/content/sample_data'"
      ],
      "metadata": {
        "id": "uMPvbkqgT0x-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = mkdir(root,'IDs_Views')\n",
        "csv_lst = list(os.walk(path))[0][2]\n",
        "path = mkdir(root,'Exif')\n",
        "for id_csv in csv_lst:\n",
        "    \n",
        "    file_path = path + '/' + id_csv.replace('id','exif')\n",
        "    exist = os.path.exists(file_path)\n",
        "    if exist:\n",
        "        print('FILE: %s ALREADY ABSORBED !' %id_csv)\n",
        "        pass\n",
        "    else:\n",
        "        print('CRAWLING ON : %s...' %id_csv)\n",
        "        dline(0)\n",
        "        \n",
        "        mkdir(root,'IDs_Views')\n",
        "        df_pic = pd.read_csv(id_csv,sep=',',engine='python')\n",
        "        df_pic.columns = ['pic_id','Views','tag']\n",
        "        df_pic = df_pic.drop_duplicates().sort_values('Views',ascending=False).reset_index()\n",
        "        del df_pic['index']\n",
        "        \n",
        "        path = mkdir(root,'Exif')\n",
        "        get_exif(df_pic,id_csv,api_key,api_secret)\n",
        "        dline(1)\n",
        "print('FINISH !!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m7eVbrWT5RX",
        "outputId": "108483f6-4e95-48b1-8876-968d3292625d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRAWLING ON : clouds_id.csv...\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "GETTING INFO: 494 , DROP_NAN: 92 , TOTAL: 586 , TIME CONSUMED: 8.68s\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "FILE: clouds_exif.csv SAVED !\n",
            "SIZE: 494\n",
            "----------------------------------------------------------------------------------\n",
            "FINISH !!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Geo info\n",
        "def get_geo(df_pic,file_name,api_key,api_secret):\n",
        "    st = time.process_time()\n",
        "    file_name = file_name.replace('id','geo')\n",
        "    df_info = pd.DataFrame(columns=['pic_id','latitude','longitude','county','region','country'])\n",
        "    df_info.to_csv(file_name,sep=',',index=None)\n",
        "    total = 0\n",
        "    amount = 0\n",
        "    drop_nan = 0\n",
        "    \n",
        "    for i in range(len(df_pic.index)):\n",
        "        \n",
        "        if amount < 100000:\n",
        "            try:\n",
        "                flickr=flickrapi.FlickrAPI(api_key,api_secret,format='parsed-json')\n",
        "                pic_geo = flickr.photos.geo.getLocation(photo_id=df_pic['pic_id'].iloc[i])\n",
        "                geo = pic_geo['photo']['location']\n",
        "                \n",
        "                for loc in geo:\n",
        "                    if loc == 'latitude':\n",
        "                        df_info[loc] = pd.Series(geo[loc])\n",
        "                    if loc == 'longitude':\n",
        "                        df_info[loc] = pd.Series(geo[loc])\n",
        "                    if loc == 'county':\n",
        "                        df_info[loc] = pd.Series(geo[loc]['_content'])\n",
        "                    if loc == 'region':\n",
        "                        df_info[loc] = pd.Series(geo[loc]['_content'])\n",
        "                    if loc == 'country':\n",
        "                        df_info[loc] = pd.Series(geo[loc]['_content'])\n",
        "                        \n",
        "                amount += 1\n",
        "                df_info['pic_id'] = df_pic['pic_id'].iloc[i]\n",
        "                df_info.to_csv(file_name,sep=',',index=None,header=None,mode='a')\n",
        "            except:\n",
        "                drop_nan += 1\n",
        "                pass\n",
        "            \n",
        "        total += 1\n",
        "        st_info = round(time.process_time()-st,2)\n",
        "        print('\\rGETTING GEO: {0} , DROP_NAN: {1} , TOTAL: {2} , TIME CONSUMED: {3}s'.format(amount,drop_nan,total,st_info),end='',flush=True)\n",
        "        #time.sleep(1)\n",
        "    dline(2)\n",
        "    print('FILE: %s SAVED !' %file_name)\n",
        "    print('SIZE: %i' %amount)"
      ],
      "metadata": {
        "id": "s2quRA8iUBiz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '404afab90a2381ab68c53efba4d3cb44'\n",
        "api_secret = 'e13d4f79198b64c7'\n",
        "root = '/content/sample_data'"
      ],
      "metadata": {
        "id": "qJQsNTZ5XXkL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = mkdir(root,'IDs_Views')\n",
        "csv_lst = list(os.walk(path))[0][2]\n",
        "path = mkdir(root,'Geo')\n",
        "\n",
        "for id_csv in csv_lst:  \n",
        "    \n",
        "    file_path = path + '/' + id_csv.replace('id','exif')\n",
        "    exist = os.path.exists(file_path)\n",
        "    \n",
        "    if exist:\n",
        "        print('FILE: %s ALREADY ABSORBED !' %id_csv)\n",
        "        pass\n",
        "    else:\n",
        "        print('CRAWLING ON : %s...' %id_csv)\n",
        "        dline(0)\n",
        "        \n",
        "        mkdir(root,'IDs_Views')\n",
        "        df_pic = pd.read_csv(id_csv,sep=',',engine='python')\n",
        "        df_pic.columns = ['pic_id','Views','tag']\n",
        "        df_pic = df_pic.drop_duplicates().sort_values('Views',ascending=False).reset_index()\n",
        "        del df_pic['index']\n",
        "        \n",
        "        path = mkdir(root,'Geo')\n",
        "        get_geo(df_pic,id_csv,api_key,api_secret)\n",
        "        dline(1)\n",
        "print('FINISH !!!')"
      ],
      "metadata": {
        "id": "tKKg1B9FawUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fde6e9-900d-4eec-de52-9e82a617b9da"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRAWLING ON : clouds_id.csv...\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "GETTING GEO: 375 , DROP_NAN: 211 , TOTAL: 586 , TIME CONSUMED: 7.3s\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "FILE: clouds_geo.csv SAVED !\n",
            "SIZE: 375\n",
            "----------------------------------------------------------------------------------\n",
            "FINISH !!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mkdir(root,folder=''):\n",
        "    path = root+'/'+folder\n",
        "    folder = os.path.exists(path)\n",
        "    if not folder:\n",
        "        os.makedirs(path)\n",
        "        os.chdir(path)\n",
        "    else:\n",
        "        os.chdir(path)\n",
        "        pass\n",
        "    return path"
      ],
      "metadata": {
        "id": "cUhYwxnlhJ8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaned ID\n",
        "root = '/content/sample_data'\n",
        "path = mkdir(root,'IDs_Views')\n",
        "csv_lst = list(os.walk(path))[0][2]\n",
        "df_id = pd.DataFrame()\n",
        "\n",
        "for csv in csv_lst:\n",
        "    df = pd.DataFrame()\n",
        "    df = pd.read_csv(csv,sep=',',engine='python')\n",
        "    df.columns = ['pic_id','Views','tag']\n",
        "    tag = df['tag'].iloc[0]\n",
        "    print('COLUMNS ATTACHED TO: %s' %csv)\n",
        "    df = df.drop_duplicates()\n",
        "    print('REMAINING:',len(df.index))\n",
        "    dline(2)\n",
        "    df = df.groupby('pic_id').sum()\n",
        "    df['tag'] = tag\n",
        "    df = df.sort_values('Views',ascending=False).reset_index()\n",
        "    \n",
        "    print(df.head())\n",
        "    dline(2)\n",
        "    print('DUPLICATES DROPED: %s' %csv)\n",
        "    print('REMAINING:',len(df.index))\n",
        "    dline(2)\n",
        "    path = mkdir(root,'IDs_Views_Cleaned')\n",
        "    df.to_csv(csv,sep=',',index=None)\n",
        "    path = mkdir(root,'IDs_Views')\n",
        "    df_id = pd.concat([df_id,df])\n",
        "    print('MERGED: %s' %csv)\n",
        "    dline(1)\n",
        "\n",
        "mkdir(root)\n",
        "df_id.to_excel('ID_Merged.xlsx',index=None)\n",
        "print('ID CLEAND !!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhtxHFSEgrIQ",
        "outputId": "9c11b4f6-ce2f-48d1-a0ff-0757df425519"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COLUMNS ATTACHED TO: clouds_id.csv\n",
            "REMAINING: 586\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "        pic_id     Views     tag\n",
            "0  52789535781  104135.0  clouds\n",
            "1  52752153257  100375.0  clouds\n",
            "2  52679305192   98705.0  clouds\n",
            "3  52716318989   97528.0  clouds\n",
            "4  52732254615   74314.0  clouds\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "DUPLICATES DROPED: clouds_id.csv\n",
            "REMAINING: 586\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "MERGED: clouds_id.csv\n",
            "----------------------------------------------------------------------------------\n",
            "ID CLEAND !!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-02e801ea8eb4>:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df = df.groupby('pic_id').sum()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge\n",
        "def read_csv(root,folder):\n",
        "    path = mkdir(root,folder)\n",
        "    csv_lst = list(os.walk(path))[0][2]\n",
        "    df_merge = pd.DataFrame()\n",
        "    \n",
        "    for csv in csv_lst:\n",
        "        df = pd.DataFrame()\n",
        "        df = pd.read_csv(csv,sep=',',engine='python')        \n",
        "        dline(2)\n",
        "        df_merge = pd.concat([df_merge,df])\n",
        "        print('MERGED: %s' %csv)\n",
        "    dline(1)\n",
        "    return df_merge\n",
        "\n",
        "root = '/content/sample_data'\n",
        "df_id = read_csv(root,'IDs_Views_Cleaned')\n",
        "df_exif = read_csv(root,'Exif').drop_duplicates()\n",
        "df_geo = read_csv(root,'Geo').drop_duplicates()\n",
        "\n",
        "df_merge = pd.merge(df_id,df_exif,on=['pic_id','pic_id'],how='left')\n",
        "df_merge = pd.merge(df_merge,df_geo,on=['pic_id','pic_id'],how='left')\n",
        "\n",
        "mkdir(root)\n",
        "df_merge.fillna(np.nan,inplace=True)\n",
        "df_merge.to_csv('Clouds_Flickr_Merged.csv',sep=',',index=None)\n",
        "print(df_merge.head())"
      ],
      "metadata": {
        "id": "x2vK3V_WbPa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71a7e40-4adb-481f-dd8b-d5e6b3680ee7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "MERGED: clouds_id.csv\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "MERGED: clouds_exif.csv\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "MERGED: clouds_geo.csv\n",
            "----------------------------------------------------------------------------------\n",
            "        pic_id     Views     tag Camera_Make   Camera_Model  Exposure  \\\n",
            "0  52789535781  104135.0  clouds         NaN            NaN       NaN   \n",
            "1  52752153257  100375.0  clouds         NaN            NaN       NaN   \n",
            "2  52679305192   98705.0  clouds         NaN            NaN       NaN   \n",
            "3  52716318989   97528.0  clouds       Canon  Canon EOS 80D     0.008   \n",
            "4  52732254615   74314.0  clouds         NaN            NaN       NaN   \n",
            "\n",
            "   Aperture Exposure_Program    ISO  Metering_Mode              Flash  \\\n",
            "0       NaN              NaN    NaN            NaN                NaN   \n",
            "1       NaN              NaN    NaN            NaN                NaN   \n",
            "2       NaN              NaN    NaN            NaN                NaN   \n",
            "3       7.1       Program AE  100.0  Multi-segment  Off, Did not fire   \n",
            "4       NaN              NaN    NaN            NaN                NaN   \n",
            "\n",
            "   Focal_Length Color_Space                    Lens_Model   latitude  \\\n",
            "0           NaN         NaN                           NaN  46.654950   \n",
            "1           NaN         NaN                           NaN  57.274310   \n",
            "2           NaN         NaN                           NaN        NaN   \n",
            "3          43.0        sRGB  EF-S18-55mm f/3.5-5.6 IS STM  32.137845   \n",
            "4           NaN         NaN                           NaN        NaN   \n",
            "\n",
            "   longitude                         county          region        country  \n",
            "0   7.908298  Interlaken-Oberhasli District            Bern    Switzerland  \n",
            "1  -5.514106                       Highland        Scotland             UK  \n",
            "2        NaN                            NaN             NaN            NaN  \n",
            "3 -80.754940                       Beaufort  South Carolina  United States  \n",
            "4        NaN                            NaN             NaN            NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03WBUeUGA435",
        "outputId": "ff7d072c-7e23-4c33-aded-ec09cb13698b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.1/492.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.3.0 pymongo-4.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3nVvZm_A5Wa",
        "outputId": "63d46198-8676-4ee5-9cad-fd58ac8b0da8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19879 sha256=525be1bb47ebea5c9496ff301728093739a5d7d0656cb2d67702f9b00de04ee0\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/49/9c/44b13823eb256a3b4dff34b972f7a3c7d9910bfef269e59bd7\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "import csv"
      ],
      "metadata": {
        "id": "LVRhgpWYBB-J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient"
      ],
      "metadata": {
        "id": "79AWvAmxBFOy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/Clouds_Flickr_Merged.csv')"
      ],
      "metadata": {
        "id": "VpmX_f23BHIL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = pymongo.MongoClient(\"mongodb+srv://user1:60XRzCr4mubxCPC5@cluster0.evngzba.mongodb.net/test\")\n",
        "db = client['Flickr']\n",
        "collection = db['Clouds Image']"
      ],
      "metadata": {
        "id": "Lmwxp8xTBPfT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.to_dict(orient='records')\n",
        "collection.insert_many(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OWjPL5wBXyM",
        "outputId": "53e72121-df26-42a9-81d8-3504f9481efc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.InsertManyResult at 0x7f82483bafd0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}